# **THICK PROMPTING AS OPERATIVE EKPHRASIS: A DESIGN-STUDIES METHOD FOR GENERATIVE VISUAL ARTIFACTS AND WORLDTEXTS**

## **1\. Introduction: The Crisis of Fidelity in Generative Design**

The emergence of multimodal artificial intelligence has fundamentally disrupted the established economies of visual production, shifting the locus of creativity from manual inscription to linguistic specification. Platforms such as Midjourney, Stable Diffusion, and DALL-E have democratized the ability to produce high-fidelity imagery, yet the theoretical frameworks employed to evaluate these artifacts remain stubbornly attached to a pre-computational paradigm of representation. In current design discourse, the primary metric for evaluating a prompt is "representational fidelity"—a utilitarian assessment of whether the generated output accurately reflects the semantic content of the input text. This instrumental view creates a crisis of fidelity, where the complex, performative negotiation between human intent and machine latency is reduced to a binary of success or failure, ignoring the profound ontological shift occurring in the space between the word and the image.1

This report argues that fidelity is an insufficient category for understanding the generative capability of multimodal systems. Instead, we propose that the interaction between the prompt and the model is best understood as **operative ekphrasis**. This concept marks a historical and technological rupture in the text–image relationship. Unlike classical ekphrasis, which seeks to describe an existing visual object through language—a poem describing a painting—operative ekphrasis uses language to *perform* the image into existence. In the computational environment of the neural network, the text does not represent the image; the text processes the image. The prompt is an operation that navigates a high-dimensional vector space to manifest a visual artifact.3

To operationalize this theoretical insight for the field of design studies, we introduce the method of **Thick Prompting**. Drawing on Clifford Geertz’s anthropological distinction between "thin description" (the observation of a physical act) and "thick description" (the interpretation of that act’s meaningful context), we reframe the prompt not as a command line but as a dense, interpretive "worldtext".5 Thick Prompting treats the input string as a heterogeneous stack of natural language, structural tags, parametric constraints, and encoded styles (such as JSON or XML schemas). This method privileges the *construction* of the prompt as a design act in itself, moving beyond the "slot machine" mentality of randomized generation toward a ritualized workflow of navigation, revision, and curation.7

The implications of this shift extend beyond mere technical proficiency. By situating multimodal prompting within a genealogy that stretches from Homer’s description of the Shield of Achilles to the "point\_worldtext" entities of contemporary game engines, we reveal the prompt as a tool for world-building.9 The "worldtext" is a textual object that contains the logic, physics, and aesthetics of a simulated reality. When a designer engages in Thick Prompting, they are not merely asking for a picture; they are writing the code for a temporary cosmos. This report serves two primary functions: first, to establish the theoretical validity of operative ekphrasis as a lens for generative AI; and second, to provide actionable, rigorous guidelines for Thick Prompting as a stable design methodology that transcends the volatility of evolving platforms.

## **2\. Operative Ekphrasis: From Representation to Performance**

To understand the generative prompt as a design material, one must first deconstruct the history of the text-image relationship. The transition from analog media to digital computation has not merely accelerated the production of images; it has collapsed the ontological distinction between the verbal and the visual, creating a new condition of "performative" textuality.

### **2.1 The Historical Collapse of the Text-Image Distinction**

Aesthetic theory has traditionally been predicated on a strict separation of media. Gotthold Ephraim Lessing, in his seminal work *Laocoön*, argued for a fundamental boundary between poetry (an art of time) and painting (an art of space). In this framework, text unfolds sequentially, while images are perceived simultaneously. Ekphrasis was the rhetorical device used to bridge this divide—a verbal representation of a visual representation. It was a gesture of "ekphrastic hope," the desire for language to make the absent image present to the mind’s eye, countered by "ekphrastic fear," the anxiety that the visual might overwhelm or displace the verbal.2

In the digital era, this separation began to erode, but the nature of the erosion depends on the specific computational paradigm. Hannes Bajohr identifies a crucial distinction between "sequential" and "connectionist" digitality. In the sequential paradigm (classical computing), code produces images, but the code (syntax) remains distinct from the output (pixel). A script written in Python *causes* an image to appear, but the script does not *resemble* the image, nor does it share a mathematical space with it. This is a "mimetic" relationship where text instructs the machine to draw.4

The "connectionist" paradigm of multimodal AI—exemplified by CLIP (Contrastive Language-Image Pre-training) and diffusion models—represents a radical departure. In these systems, text and images are encoded into the *same* latent space. The word "dog" and the image of a dog are converted into mathematical vectors that reside in close proximity within a multi-dimensional conceptual map. Here, the distinction between text and image collapses not just metaphorically, but technically. They are both data. This collapse enables **operative ekphrasis**: the text acts directly on the substrate of the image. The description is no longer a representation of a prior object; it is the *mechanism* of the object's production. The prompt performs the image by navigating the latent associations (the "artificial semantics") established during the model's training.4

### **2.2 Homer’s Shield as the Primal Worldtext**

The concept of operative ekphrasis allows us to revisit the history of literature and identify "proto-generative" texts. The most significant of these is the description of the Shield of Achilles in Book 18 of Homer’s *Iliad*. This passage is often cited as the first instance of ekphrasis in Western literature, but it differs fundamentally from later descriptions of static art objects (such as Keats’ *Ode on a Grecian Urn*). Homer does not describe the shield as a finished product; he narrates the *process* of Hephaestus forging it.9

Homer describes the god layering metals, creating landscapes, and animating scenes of "two cities," "a wedding procession," and "ploughmen turning the earth." The description foregrounds the *making* (poiesis). In this sense, the passage functions as a **worldtext**—a set of instructions that generates a cosmos. The poet (Homer) provides the prompt ("Make a shield with the earth, the sky, and the sea"), and the divine smith (Hephaestus) executes the prompt, forging the visual artifact into existence. The resulting object is not just a picture; it is a dynamic system containing narratives, motion, and sound, encapsulated within the static medium of the shield.15

This ancient example mirrors the operation of modern generative AI. The user acts as the poet, providing the textual specification, while the model acts as Hephaestus, the "black box" artisan that executes the complex, opaque operations required to render the specification into visual form. Just as the Shield of Achilles contains a representation of the entire cosmos, the latent space of a generative model contains a statistical representation of the entire visual culture it was trained on. The prompt is the key that unlocks specific regions of this "latent cosmos," allowing the designer to instantiate a worldtext.11

### **2.3 Algorithmic Remediation and the Feedback Loop**

Operative ekphrasis also functions as a mechanism of **remediation**. Jay David Bolter and Richard Grusin defined remediation as the way in which new media refashion earlier media. Generative AI is arguably the ultimate remediation machine. It digests the entire history of human visual production—photography, oil painting, charcoal sketching, 3D rendering—and dissolves it into a statistical soup of weights and biases. When a prompt requests an image "in the style of Van Gogh," the model does not retrieve a Van Gogh painting; it *remediates* the statistical patterns of Van Gogh's brushstrokes and color palettes, synthesizing them with the semantic subject of the prompt.1

This process is recursive. As AI-generated images flood the internet, they are scraped and fed back into future training datasets, creating a feedback loop where the model begins to remediate itself. This "autophagous" cycle (AI eating itself) presents a risk of aesthetic collapse or "model collapse," where the nuanced diversity of human visual culture is smoothed out into a generic "AI aesthetic".18 Thick Prompting emerges here as a critical intervention. By using dense, specific, and structurally complex prompts, the designer forces the model to deviate from its generic tendencies, retrieving specific historical or stylistic lineages that might otherwise be lost in the statistical average. The "thick" prompt resists the entropy of the feedback loop.

### **2.4 The Performative Turn in Digital Aesthetics**

The shift to operative ekphrasis aligns with a broader "performative turn" in digital aesthetics. Scholars like Katherine Hayles have argued that electronic text is inherently processual—it *does* things rather than just *saying* things.4 In the context of "multimodal AI," this performance is characterized by the transmutation of sign systems. The prompt is a signifier that does not point to a signified concept in the mind of a reader, but rather triggers a probabilistic calculation in the "mind" of the network.

This performance creates a new type of authorship. The designer is not the sole author of the image (since the model synthesizes the pixel data), nor is the machine the author (since it has no intent). Instead, authorship is located in the **curatorial performance** of the prompt. The "Thick Prompt" is the script for this performance. It orchestrates the model's capabilities, directing the "artificial semantics" toward a specific, intentional outcome. The value of the design lies not in the final JPG, but in the sophistication of the prompt strategy that produced it—the "operative" logic that successfully navigated the latent space.20

## ---

**3\. Thick Prompting: A Design-Studies Methodology**

If operative ekphrasis provides the theoretical grounding for generative AI, **Thick Prompting** provides the methodological framework for its application. We derive this term from Clifford Geertz’s concept of "thick description," a foundational method in ethnography. Geertz, borrowing from Gilbert Ryle, distinguished between a "thin description" of a physical movement (e.g., a rapid contraction of the eyelid) and a "thick description" that accounts for the context, intent, and social meaning of that movement (e.g., a conspiratorial wink, a mockery of a wink, or a nervous twitch).5

In the context of generative AI, a "thin prompt" is a raw, transactional request for content ("A cat sitting on a chair"). It relies entirely on the model's default assumptions—its statistical "thinness"—to fill in the gaps. A "thick prompt," by contrast, is a layered, interpretive structure that accounts for the "stratified hierarchy of meaningful structures" within the latent space. It explicates the context, the style, the medium, the lighting, and the semiotic intent of the generation. Thick Prompting is not merely about adding *more* words; it is about adding *meaningful structure* that constrains the ambiguity of the generative process.22

### **3.1 The Prompt as a Heterogeneous Stack**

Traditional prompting often treats the input as a single string of natural language. Thick Prompting re-conceptualizes the prompt as a **heterogeneous stack** of distinct functional layers. Just as a web page is composed of HTML (structure), CSS (style), and JavaScript (behavior), a Thick Prompt is composed of modular components that address different dimensions of the generative operation.

The following table outlines the layers of a Thick Prompt stack:

| Layer | Function | Digital Equivalent | Example Components |
| :---- | :---- | :---- | :---- |
| **Semantic Core** | Defines the primary subject and action. | The "Noun/Verb" | "An astronaut riding a horse," "A cybernetic organism." |
| **Stylistic/Aesthetic** | Defines the remediation lineage. | The "Adjective/Reference" | "In the style of 1980s synthwave," "Chiaroscuro lighting," "Oil on canvas." |
| **Structural/Format** | Defines geometric and technical constraints. | The "Syntax/Layout" | "Isometric view," "Macro lens," "16:9 aspect ratio," "JSON schema." |
| **Parametric Control** | Controls model behavior and variability. | The "Settings/Hyperparameters" | \--stylize 700, \--chaos 20, \--seed 12345, "Temperature: 0.7". |
| **Negative Constraints** | Defines exclusion (what the world is *not*). | The "Filter/Mask" | \--no text, blur, watermarks, "Negative Prompt: deformed hands." |
| **Meta-Instruction** | Defines the persona/role of the AI. | The "System Prompt" | "You are an expert cinematographer," "Act as a visual semiotician." |

This layered approach transforms the prompt from a sentence into a **design specification**. It allows the designer to manipulate specific variables independently (e.g., changing the "Stylistic" layer while keeping the "Semantic Core" locked) to explore the latent space systematically.24

### **3.2 Structured Prompting and Artificial Semantics**

One of the key innovations in Thick Prompting is the integration of **structured data formats**, particularly JSON (JavaScript Object Notation), into the prompting workflow. While natural language is expressive, it is often ambiguous. Models like GPT-4 and Midjourney can interpret structured data as a form of "cognitive scaffolding," which forces the model to organize its generative process according to a strict schema.8

For example, instead of writing a long, convoluted paragraph, a designer using Thick Prompting might input a JSON object:

JSON

{  
  "scene": {  
    "subject": "Cyberpunk detective",  
    "action": "Examining a glowing artifact",  
    "location": "Neo-Tokyo alleyway"  
  },  
  "atmosphere": {  
    "weather": "Acid rain",  
    "lighting": "Neon signage reflections",  
    "mood": "Melancholic noir"  
  },  
  "technical": {  
    "medium": "Digital painting",  
    "style\_ref":,  
    "camera": "High angle, 35mm lens"  
  }  
}

This structure creates a "Thick" interaction because it explicates the relationships between elements. It tells the model that "Acid rain" is part of the "atmosphere," not the "subject." Research indicates that such structured prompting techniques significantly improve the model's adherence to complex instructions and reduce the rate of "hallucination" (unintended elements).27 It effectively aligns the "artificial semantics" of the model—its internal statistical associations—with the structured intent of the user.

### **3.3 The Ritual of Execution: Navigability, Revisability, Discussability**

Thick Prompting is not a "fire and forget" action; it is a ritualized workflow. Because generative models are probabilistic (stochastic), a single execution is statistically insignificant. A "Thick" workflow involves:

1. **Navigability:** Using the prompt stack to move through latent space. By fixing the "Seed" parameter and changing only the "Stylistic" layer, the designer can "travel" through different aesthetic worlds while maintaining the same semantic subject. This makes the latent space navigable rather than random.29  
2. **Revisability:** The modular nature of the Thick Prompt allows for precise revision. If the lighting is wrong, the designer targets the "Atmosphere" block of the JSON or the specific parametric weight (e.g., lighting::2) without rewriting the entire prompt. This creates a version control system for visual generation.30  
3. **Discussability:** A Thick Prompt serves as a boundary object for design teams. Unlike a vague natural language description, a structured prompt stack can be shared, critiqued, and iterated upon by a team. It makes the "black box" of the AI transparent enough to be a subject of collaborative design discourse.5

### **3.4 Chain of Density (CoD) as Recursive Thickening**

A specific technique within Thick Prompting is the **Chain of Density (CoD)**. Originally developed for text summarization, CoD involves an iterative process of "densifying" the information content of a prompt without increasing its length. In the context of visual generation, CoD is used to combat the model’s tendency to "forget" details in long prompts.31

The CoD workflow for operative ekphrasis involves:

* **Step 1 (Sparse):** Generate a baseline prompt ("A castle on a hill").  
* **Step 2 (Identify):** Identify missing semantic entities (texture, historical era, lighting, weather).  
* **Step 3 (Fuse):** Fuse these entities into the prompt, replacing vague terms with dense descriptors (Change "castle" to "dilapidated 12th-century fortress," change "hill" to "jagged basalt crag").  
* **Step 4 (Iterate):** Repeat the process until the prompt achieves maximum "entity density" per token.

This recursive thickening forces the model to access more specific, lower-frequency vectors in the latent space, resulting in images that are visually richer and less generic. It operationalizes Geertz’s "thick description" by layering meaning onto the initial "thin" request.33

### **3.5 The "Worldtext" in Design Practice**

The ultimate output of Thick Prompting is not just an image, but a **Worldtext**. In game design, the entity point\_worldtext is used to embed textual information directly into the 3D geometry of a level.10 In literary theory, the "worldtext" refers to the interpretative framework through which the world is read.35 In generative design, the Worldtext is the comprehensive prompt stack that defines the *rules* of the generated reality.

When a designer establishes a "consistent character" using a specific prompt structure (DNA) and places that character into different "scenes" (Context) using a consistent "style" (System Prompt), they are essentially building a game engine out of text.37 The prompt becomes the physics engine, the lighting engine, and the casting director of the simulated world. This creates a cohesive "Umwelt" or environment where the visual artifacts are consistent with one another, effectively simulating a persistent reality through operative ekphrasis.39

## ---

**4\. Technical Execution: Prompt Differentials and Sensitivity Analysis**

While the previous sections established the theoretical and methodological framework of Thick Prompting, this section details the technical execution. To transform prompting from an intuitive art into a rigorous design science, we must employ quantitative and analytical techniques: specifically, **Prompt Sensitivity Analysis** and **Ablation Studies**. These methods allow designers to measure the "volatility" of the latent space and determine exactly which parts of a "thick" prompt are driving the visual output.

### **4.1 Prompt Sensitivity Analysis**

Prompt sensitivity refers to the degree to which a generative model’s output changes in response to minor variations in the input prompt. A model with high sensitivity might produce a completely different image if a single adjective is changed; a model with low sensitivity might ignore subtle instructions entirely. For the designer, understanding this sensitivity is crucial for control.40

We propose a formal **Prompt Differential** workflow to map this sensitivity:

1. **Baseline Generation:** Establish a "Thick Prompt" stack and generate a baseline image using a fixed seed.  
2. **Variable Isolation:** Change *one* variable in the stack (e.g., the "medium" in the JSON schema) while holding all other variables and the seed constant.  
3. **Differential Measurement:** Compare the new output to the baseline. This can be done qualitatively (visual inspection) or quantitatively using metrics like **SRCC (Spearman Rank Correlation Coefficient)** or **PLCC (Pearson Linear Correlation Coefficient)**, which measure the correlation between the prompt structure and the image quality/features.42  
4. **Sensitivity Mapping:** By repeating this process across different layers of the stack, the designer creates a "map" of the model's responsiveness. They might discover, for instance, that the model is highly sensitive to lighting keywords ("neon," "chiaroscuro") but relatively insensitive to camera lens descriptors ("35mm," "85mm").

This process reveals the "Prompt-Dominant" vs. "Model-Dominant" features of the generation. A "Prompt-Dominant" feature is one where the user has high control; a "Model-Dominant" feature is one where the AI’s internal biases override the user’s instructions. Thick Prompting aims to maximize Prompt-Dominance.41

### **4.2 Ablation Studies in Prompt Engineering**

Ablation is a technique borrowed from neuroscience and machine learning research, where parts of a system are removed to study the function of the remaining components. In the context of Thick Prompting, an **Ablation Study** involves systematically removing layers of the prompt stack to validate their necessity and effect.43

A typical ablation workflow for a visual artifact might look like this:

| Iteration | Prompt Configuration | Observation/Result | Insight |
| :---- | :---- | :---- | :---- |
| **Full Stack** | Semantic \+ Style \+ Tech \+ Params | Highly detailed, specific style, correct aspect ratio. | The "Target" Worldtext. |
| **Ablation A** | *Remove Style Layer* | Semantic content remains, but aesthetic reverts to generic "photorealism." | The "Style" layer effectively overrides the default aesthetic. |
| **Ablation B** | *Remove Structural/JSON* | Content becomes disorganized; elements float or blend incorrectly. | The JSON structure provides crucial spatial/logical coherence. |
| **Ablation C** | *Remove Negative Constraints* | Artifacts appear (text, blur, extra limbs). | Negative prompts are essential for "cleaning" the latent space. |

Research indicates that simpler tasks benefit linearly from added prompt techniques, while complex tasks show "synergistic gains" where the combination of layers (e.g., CoT \+ Few-Shot \+ Constraints) produces results better than the sum of their parts.44 By conducting ablation studies, designers can "prune" their Thick Prompts, removing superstitious or redundant keywords ("magic words" like "4k" or "trending on ArtStation" that may no longer have effect) and retaining only the functional operatives.

### **4.3 Quantifying Reliability and Consistency**

One of the major challenges in operative ekphrasis is **reliability**. Does the prompt *consistently* produce the desired worldtext, or did it get lucky once? To measure this, we employ **Consistency Scoring** within the Thick Prompting workflow.

* **Method:** Run the *same* Thick Prompt across 10-20 different random seeds.  
* **Evaluation:** Calculate the variance in the output. Are the characters consistent? Is the style stable?  
* **Metric:** We can use the **Joint Attribution Score (JAS)**, a metric that quantifies the interactive effects between the prompt and the model. A high JAS indicates that the prompt and the model are working in concert to produce the specific hallucination or feature; low reliability suggests the prompt is too "thin" to constrain the model's inherent variance.41

The goal of Thick Prompting is to achieve a **High-Reliability Worldtext**—a prompt stack that produces coherent, on-brand, and structurally sound results across a wide range of seeds and variations. This moves the practice from "artistic experimentation" to "industrial design," where reproducibility is key.

### **4.4 Advanced Techniques: Parametric Weighting and Syntax**

Technical execution also involves mastering the specific **syntax of weights** provided by generative platforms. This is the "punctuation" of operative ekphrasis.

* **Midjourney Multi-Prompting (::):** The use of double colons allows designers to assign numerical weights to different parts of the prompt (e.g., atmosphere::2, character::1). This explicitly tells the model to prioritize the "atmosphere" layer over the "character" layer, a crucial control for establishing mood.30  
* **Stable Diffusion Attention (()):** Using parentheses (e.g., (keyword:1.5)) increases the attention the model pays to specific tokens.  
* **Negative Prompting:** This is the "apophatic" theology of AI—defining the image by what it is *not*. Thick Negative Prompts (e.g., "no blur, no text, no distortion, no crop") act as a boundary fence for the latent space, preventing the generation from wandering into low-quality regions.46

By combining these syntactic controls with the semantic density of "Thick Description," designers gain fine-grained control over the *performance* of the image.

## **5\. Design Implications: The Worldtext and the Ethical Interface**

The shift to Thick Prompting and operative ekphrasis has profound implications for the identity of the designer, the nature of the artifact, and the ethics of production.

### **5.1 The Death of the "User" and the Rise of the "Director"**

Thick Prompting fundamentally alters the agency of the human operator. The interaction is no longer that of a "user" consuming a service (typing a query, getting a result). Instead, the human assumes the role of a **Director** or **Curator**. The skill set required is not manual dexterity (the ability to draw) but **verbal dexterity**, **systemic thinking**, and **curatorial judgment**.47 The designer must be able to:

1. **Articulate** visual concepts in precise, structured language (operative ekphrasis).  
2. **Orchestrate** the "heterogeneous stack" of the prompt (technical direction).  
3. **Navigate** the variations of the latent space to select the optimal instance (curation). This shifts design education toward the liberal arts—rhetoric, literature, art history, and anthropology become the primary tools for "engineering" visual artifacts.48

### **5.2 The Worldtext as an Ethical Interface**

If the prompt is a worldtext, then the biases inherent in the model’s training data represent the "laws of physics" of that world. A "thin" prompt yields to these biases; if a user prompts for "a doctor," the model’s default worldtext (based on scraped internet data) will likely produce a white male. Thick Prompting functions as an **ethical intervention**. By explicitly specifying diversity, cultural context, and counter-narratives within the "heterogeneous stack," the designer can override the default normative assumptions of the latent space. Operative ekphrasis thus becomes a tool for **critical fabrication**—using the generative capacity of the model to critique and reshape its own underlying ideologies.19 For example, a Thick Prompt might explicitly construct a "Solarpunk Nairobi" worldtext, forcing the model to synthesize African architectural modernism with green technology, actively resisting the "cyberpunk/dystopian" bias often found in sci-fi training data. The "thickness" of the description is the mechanism of resistance.

### **5.3 Remediation and the "Double Logic"**

Bolter and Grusin’s theory of remediation describes a "double logic" of **immediacy** (making the medium invisible) and **hypermediacy** (foregrounding the medium).17 Generative AI often strives for immediacy—the "perfect" photorealistic image where the AI is invisible. Thick Prompting, however, often embraces hypermediacy. By using stylized tokens ("glitch art," "halftone," "wireframe"), the designer calls attention to the *mediated* nature of the image. The "point\_worldtext" entity in game design serves as a metaphor here: it is text that is *in* the world, visible and operative. Thick Prompting places the text back into the visual field, acknowledging that in the era of AI, the image is always already a text.

## ---

**6\. Conclusion**

This report has established that the current paradigm of "fidelity" is inadequate for evaluating the creative potential of multimodal AI. By reframing the prompt as **operative ekphrasis**, we recognize that the text-image relationship has shifted from representation (describing what is there) to performance (making what is not there). The text operates on the latent space to summon the visual artifact.

To harness this power, we have proposed **Thick Prompting** as a formalized design method. Moving beyond the "thin," transactional query, Thick Prompting constructs "worldtexts"—heterogeneous, structured, and semantically dense stacks of instructions that navigate the generative cosmos with intent. We have detailed the technical architecture of this method—using JSON schemas, Chain of Density, and parameter tuning—and demonstrated how "Prompt Sensitivity Analysis" and "Ablation Studies" can transform prompting into a rigorous, scientific practice.

Ultimately, Thick Prompting reclaims human agency in the age of the algorithm. It reminds us that the machine does not "imagine"; it calculates. It is the human "thick description"—the injection of meaning, context, and culture—that transforms that calculation into a world. As we look to the future of design, the ability to write these "worldtexts" will become as fundamental as the ability to draw a line. The prompt is not just a caption; it is the code of culture.

## ---

**References & Data Sources**

This report synthesizes concepts and data from the following research snippets:

* **Operative Ekphrasis & Text-Image Theory:**.2  
* **Thick Description & Geertz:**.5  
* **Remediation & Bolter:**.1  
* **Worldtext:**.10  
* **Thick Prompting Techniques (JSON, CoD, Structure):**.7  
* **Sensitivity Analysis & Ablation:**.40  
* **AI Ethics & Biases:**.18

#### **Works cited**

1. Generative Imagery as Media Form and Research Field, accessed January 26, 2026, [https://d-nb.info/1333411855/34](https://d-nb.info/1333411855/34)  
2. AI Generative Art as Algorithmic Remediation \- media/rep, accessed January 26, 2026, [https://mediarep.org/bitstreams/34b804d2-c446-4440-b8b8-e5b6af0370ac/download](https://mediarep.org/bitstreams/34b804d2-c446-4440-b8b8-e5b6af0370ac/download)  
3. The Dissolution of the Text-Image Distinction in Multimodal AI, accessed January 26, 2026, [https://german.uic.edu/events/operative-ekphrasis-the-dissolution-of-the-text-image-distinction-in-multimodal-ai/](https://german.uic.edu/events/operative-ekphrasis-the-dissolution-of-the-text-image-distinction-in-multimodal-ai/)  
4. Operative ekphrasis: the collapse of the text/image distinction in ..., accessed January 26, 2026, [https://www.tandfonline.com/doi/full/10.1080/02666286.2024.2330335](https://www.tandfonline.com/doi/full/10.1080/02666286.2024.2330335)  
5. Mastering Thick Description in Qualitative Research (with Examples), accessed January 26, 2026, [https://heymarvin.com/resources/thick-description-in-qualitative-research/](https://heymarvin.com/resources/thick-description-in-qualitative-research/)  
6. Thick Description: \- Toward an Interpretive Theory of Culture 1973, accessed January 26, 2026, [https://people.ucsc.edu/\~ktellez/geertz1973.pdf](https://people.ucsc.edu/~ktellez/geertz1973.pdf)  
7. RACE Model ChatGPT: Better Prompts with Structure 2026, accessed January 26, 2026, [https://www.clickforest.com/en/blog/race-model-chatgpt-prompts](https://www.clickforest.com/en/blog/race-model-chatgpt-prompts)  
8. JSON Prompting for LLMs: A Practical Guide with Python Coding ..., accessed January 26, 2026, [https://www.marktechpost.com/2025/08/23/json-prompting-for-llms-a-practical-guide-with-python-coding-examples/](https://www.marktechpost.com/2025/08/23/json-prompting-for-llms-a-practical-guide-with-python-coding-examples/)  
9. The trajectory of ancient ekphrasis\* \- Edice E, accessed January 26, 2026, [https://edicee.ucl.cas.cz/images/data/sborniky/2014/opaj/6.pdf](https://edicee.ucl.cas.cz/images/data/sborniky/2014/opaj/6.pdf)  
10. point\_worldtext \- Valve Developer Community, accessed January 26, 2026, [https://developer.valvesoftware.com/wiki/Point\_worldtext](https://developer.valvesoftware.com/wiki/Point_worldtext)  
11. AI Generative Art as Algorithmic Remediation \- media/rep, accessed January 26, 2026, [https://mediarep.org/bitstreams/db11c2d8-a3c1-427d-911e-7bd788e5facd/download](https://mediarep.org/bitstreams/db11c2d8-a3c1-427d-911e-7bd788e5facd/download)  
12. Operative ekphrasis: The collapse of the text/image distinction in ..., accessed January 26, 2026, [https://www.researchgate.net/publication/372400146\_Operative\_ekphrasis\_The\_collapse\_of\_the\_textimage\_distinction\_in\_multimodal\_AI\_PLEASE\_REFER\_TO\_PUBLISHED\_VERSION](https://www.researchgate.net/publication/372400146_Operative_ekphrasis_The_collapse_of_the_textimage_distinction_in_multimodal_AI_PLEASE_REFER_TO_PUBLISHED_VERSION)  
13. the collapse of the text/image distinction in multimodal AI, accessed January 26, 2026, [https://www.researchgate.net/publication/380812173\_Operative\_ekphrasis\_the\_collapse\_of\_the\_textimage\_distinction\_in\_multimodal\_AI](https://www.researchgate.net/publication/380812173_Operative_ekphrasis_the_collapse_of_the_textimage_distinction_in_multimodal_AI)  
14. The Ekphrastic Gaze in British Postmodern Fiction, accessed January 26, 2026, [https://d-nb.info/1214887643/34](https://d-nb.info/1214887643/34)  
15. The Beginnings of "Ekphrasis" Author(s): James A. Francis Source, accessed January 26, 2026, [https://blogs.baruch.cuny.edu/manmademonsters/wp-content/blogs.dir/4021/files/2015/08/The-Beginnings-of-Ekphrasis.pdf](https://blogs.baruch.cuny.edu/manmademonsters/wp-content/blogs.dir/4021/files/2015/08/The-Beginnings-of-Ekphrasis.pdf)  
16. IMAGE. Zeitschrift für interdisziplinäre Bildforschung (1/2023), accessed January 26, 2026, [https://www.researchgate.net/profile/Lukas-Wilde/publication/371155801\_Generative\_Imagery\_Towards\_a\_'New\_Paradigm'\_of\_Machine\_Learning-Based\_Image\_Production/links/6475fb746fb1d1682b1cc99c/Generative-Imagery-Towards-a-New-Paradigm-of-Machine-Learning-Based-Image-Production.pdf?origin=scientificContributions](https://www.researchgate.net/profile/Lukas-Wilde/publication/371155801_Generative_Imagery_Towards_a_'New_Paradigm'_of_Machine_Learning-Based_Image_Production/links/6475fb746fb1d1682b1cc99c/Generative-Imagery-Towards-a-New-Paradigm-of-Machine-Learning-Based-Image-Production.pdf?origin=scientificContributions)  
17. “Platform Realism”. AI Image Synthesis and the Rise of Generic ..., accessed January 26, 2026, [https://journals.openedition.org/transbordeur/2299?lang=en](https://journals.openedition.org/transbordeur/2299?lang=en)  
18. When AI Eats Itself \- Fanatic Design, accessed January 26, 2026, [https://fanatic.co.uk/blog/when-ai-eats-itself/](https://fanatic.co.uk/blog/when-ai-eats-itself/)  
19. The Shady Light of Art Automation \- arXiv, accessed January 26, 2026, [https://arxiv.org/pdf/2502.19107](https://arxiv.org/pdf/2502.19107)  
20. Writing at a Distance: Notes on Authorship and Artificial Intelligence, accessed January 26, 2026, [https://hannesbajohr.de/en/wp-content/uploads/sites/2/2023/06/Bajohr-Writing-at-a-Distance.pdf](https://hannesbajohr.de/en/wp-content/uploads/sites/2/2023/06/Bajohr-Writing-at-a-Distance.pdf)  
21. Thinking with AI Machine Learning the Humanities, accessed January 26, 2026, [http://openhumanitiespress.org/books/download/Bajohr\_2025\_Thinking-With-AI.pdf](http://openhumanitiespress.org/books/download/Bajohr_2025_Thinking-With-AI.pdf)  
22. Thick description: moving beyond the thin soap, accessed January 26, 2026, [https://www.su.se/download/18.6f0acc5f19a7bc9dc1f56fe3/1764612184406/Alvesson,%20Mats,%20Thick%20description:%20Moving%20beyond%20the%20thin%20soapAlvesson.Thick%20description.6.10.23.pdf](https://www.su.se/download/18.6f0acc5f19a7bc9dc1f56fe3/1764612184406/Alvesson,%20Mats,%20Thick%20description:%20Moving%20beyond%20the%20thin%20soapAlvesson.Thick%20description.6.10.23.pdf)  
23. Brief Note on the Origins, Evolution, and Meaning of the Qualitative ..., accessed January 26, 2026, [https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=1666\&context=tqr](https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=1666&context=tqr)  
24. The Complete Guide to Prompting Different AI Models \- Medium, accessed January 26, 2026, [https://medium.com/@pramida.tumma/the-complete-guide-to-prompting-different-ai-models-9167a2657490](https://medium.com/@pramida.tumma/the-complete-guide-to-prompting-different-ai-models-9167a2657490)  
25. Prompt Architectures: An Overview of structured prompting strategies, accessed January 26, 2026, [https://medium.com/@balajibal/prompt-architectures-an-overview-of-structured-prompting-strategies-05b69a494956](https://medium.com/@balajibal/prompt-architectures-an-overview-of-structured-prompting-strategies-05b69a494956)  
26. How to Generate JSON Prompts for AI Models \- AISuperHub, accessed January 26, 2026, [https://www.aisuperhub.io/blog/how-to-generate-json-prompts-for-ai-models-a-comprehensive-guide](https://www.aisuperhub.io/blog/how-to-generate-json-prompts-for-ai-models-a-comprehensive-guide)  
27. Enhancing structured data generation with GPT-4o evaluating ..., accessed January 26, 2026, [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1558938/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1558938/full)  
28. JSON prompting for LLMs \- IBM Developer, accessed January 26, 2026, [https://developer.ibm.com/articles/json-prompting-llms/](https://developer.ibm.com/articles/json-prompting-llms/)  
29. Open Source AI Video Models Community \- ReelMind, accessed January 26, 2026, [https://reelmind.ai/blog/the-cinematic-edge-illuminating-cinematography-workshop-bundle-analysis-focus-on-craft](https://reelmind.ai/blog/the-cinematic-edge-illuminating-cinematography-workshop-bundle-analysis-focus-on-craft)  
30. What is FLUX and How to Use It for Image Generation \- MindStudio, accessed January 26, 2026, [https://www.mindstudio.ai/blog/flux](https://www.mindstudio.ai/blog/flux)  
31. Chain of Density (CoD) \- Learn Prompting, accessed January 26, 2026, [https://learnprompting.org/docs/advanced/self\_criticism/chain-of-density](https://learnprompting.org/docs/advanced/self_criticism/chain-of-density)  
32. Chain Of Density – The latest prompting technique on the block., accessed January 26, 2026, [https://medium.com/aimonks/chain-of-density-the-latest-prompting-technique-on-the-block-183fe87fa9a6](https://medium.com/aimonks/chain-of-density-the-latest-prompting-technique-on-the-block-183fe87fa9a6)  
33. What is the Chain of Density in Prompt Engineering?, accessed January 26, 2026, [https://www.analyticsvidhya.com/blog/2024/07/chain-of-density-in-prompt-engineering/](https://www.analyticsvidhya.com/blog/2024/07/chain-of-density-in-prompt-engineering/)  
34. Chain-of-Density Prompting: Pack Maximum Insight into Minimum ..., accessed January 26, 2026, [https://prompton.wordpress.com/2025/07/28/%F0%9F%9A%80-chain-of-density-prompting-pack-maximum-insight-into-minimum-words-%F0%9F%98%B1/](https://prompton.wordpress.com/2025/07/28/%F0%9F%9A%80-chain-of-density-prompting-pack-maximum-insight-into-minimum-words-%F0%9F%98%B1/)  
35. InternationalIntertextual Relations Postmodern Readings of World ..., accessed January 26, 2026, [https://www.scribd.com/doc/45283071/InternationalIntertextual-Relations-Postmodern-Readings-of-World-Politics](https://www.scribd.com/doc/45283071/InternationalIntertextual-Relations-Postmodern-Readings-of-World-Politics)  
36. Joyce: A Guide for the Perplexed 9781472543110, 9780826487919 ..., accessed January 26, 2026, [https://dokumen.pub/joyce-a-guide-for-the-perplexed-9781472543110-9780826487919-9780826487926.html](https://dokumen.pub/joyce-a-guide-for-the-perplexed-9781472543110-9780826487919-9780826487926.html)  
37. Consistent Character Generation in AI | PDF \- Scribd, accessed January 26, 2026, [https://www.scribd.com/document/689125140/2311-10093](https://www.scribd.com/document/689125140/2311-10093)  
38. Creating Consistent AI Characters Without LoRAs or ReActor, accessed January 26, 2026, [https://zanno.se/creating-consistent-ai-characters-without-loras-or-reactor/](https://zanno.se/creating-consistent-ai-characters-without-loras-or-reactor/)  
39. Diffractive Reading: New Materialism, Theory, Critique 1786613964 ..., accessed January 26, 2026, [https://dokumen.pub/diffractive-reading-new-materialism-theory-critique-1786613964-9781786613967.html](https://dokumen.pub/diffractive-reading-new-materialism-theory-critique-1786613964-9781786613967.html)  
40. How Sensitive Are Large Multimodal Models to Prompts?, accessed January 26, 2026, [https://aclanthology.org/2025.findings-emnlp.1302.pdf](https://aclanthology.org/2025.findings-emnlp.1302.pdf)  
41. Survey and analysis of hallucinations in large language models, accessed January 26, 2026, [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1622292/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1622292/full)  
42. Hierarchical Prompt Engineering and Task-Differentiated Low-Rank ..., accessed January 26, 2026, [https://www.mdpi.com/2078-2489/16/11/1006](https://www.mdpi.com/2078-2489/16/11/1006)  
43. ABGEN: Evaluating Large Language Models in Ablation Study ..., accessed January 26, 2026, [https://aclanthology.org/2025.acl-long.611v2.pdf](https://aclanthology.org/2025.acl-long.611v2.pdf)  
44. Prompt ablation study shows incremental improvements with each..., accessed January 26, 2026, [https://www.researchgate.net/figure/Prompt-ablation-study-shows-incremental-improvements-with-each-prompting-technique-on\_fig1\_389071150](https://www.researchgate.net/figure/Prompt-ablation-study-shows-incremental-improvements-with-each-prompting-technique-on_fig1_389071150)  
45. PARC: A Quantitative Framework Uncovering the Symmetries within ..., accessed January 26, 2026, [https://openaccess.thecvf.com/content/CVPR2025/papers/Schmalfuss\_PARC\_A\_Quantitative\_Framework\_Uncovering\_the\_Symmetries\_within\_Vision\_Language\_CVPR\_2025\_paper.pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Schmalfuss_PARC_A_Quantitative_Framework_Uncovering_the_Symmetries_within_Vision_Language_CVPR_2025_paper.pdf)  
46. Design principles for text-to-image generative artificial intelligence ..., accessed January 26, 2026, [https://www.tandfonline.com/doi/full/10.1080/0960085X.2026.2616042?src=](https://www.tandfonline.com/doi/full/10.1080/0960085X.2026.2616042?src)  
47. Prompting Isn't Magic — It's Design | by Ai and Automation \- Medium, accessed January 26, 2026, [https://medium.com/@nextgenai22/prompting-isnt-magic-it-s-design-8bb6ed532443](https://medium.com/@nextgenai22/prompting-isnt-magic-it-s-design-8bb6ed532443)  
48. Navigating education and work futures through generative AI, accessed January 26, 2026, [https://www.researchgate.net/publication/399773387\_Navigating\_education\_and\_work\_futures\_through\_generative\_AI\_transmaterial\_philosophy\_education\_and\_the\_algorithmic\_arts](https://www.researchgate.net/publication/399773387_Navigating_education_and_work_futures_through_generative_AI_transmaterial_philosophy_education_and_the_algorithmic_arts)  
49. History of AI \- Critical Theory‎, accessed January 26, 2026, [https://criticaltheory.info/ai/history/](https://criticaltheory.info/ai/history/)  
50. Digital ekphrasis? \- Studi di estetica, accessed January 26, 2026, [https://journals.mimesisedizioni.it/index.php/studi-di-estetica/article/download/1080/1508/](https://journals.mimesisedizioni.it/index.php/studi-di-estetica/article/download/1080/1508/)  
51. what role, if any, should clifford geertz's 'thick, accessed January 26, 2026, [https://cathryncarena.weebly.com/uploads/5/2/2/1/52219997/thick\_description.pdf](https://cathryncarena.weebly.com/uploads/5/2/2/1/52219997/thick_description.pdf)  
52. Thick Description \- Intro to Cultural Anthropology Key Term \- Fiveable, accessed January 26, 2026, [https://fiveable.me/key-terms/introduction-cultural-anthropology/thick-description](https://fiveable.me/key-terms/introduction-cultural-anthropology/thick-description)  
53. research \- Cambridge University Press & Assessment, accessed January 26, 2026, [https://www.cambridge.org/core/services/aop-cambridge-core/content/view/607F23189D88CBEC83400BD1B148CCAA/S1359135525100961a.pdf/disrupting\_design\_research\_in\_architecture\_speculating\_on\_a\_third\_phase\_of\_architectural\_design\_research.pdf](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/607F23189D88CBEC83400BD1B148CCAA/S1359135525100961a.pdf/disrupting_design_research_in_architecture_speculating_on_a_third_phase_of_architectural_design_research.pdf)  
54. (PDF) Generative Imagery as Media Form and Research Field, accessed January 26, 2026, [https://www.researchgate.net/publication/371155857\_Generative\_Imagery\_as\_Media\_Form\_and\_Research\_Field\_Introduction\_to\_a\_New\_Paradigm](https://www.researchgate.net/publication/371155857_Generative_Imagery_as_Media_Form_and_Research_Field_Introduction_to_a_New_Paradigm)  
55. The Brittle Compass: Navigating LLM Prompt Sensitivity in Slovak ..., accessed January 26, 2026, [https://acl-bg.org/proceedings/2025/LowResNLP%202025/pdf/2025.lowresnlp-1.10.pdf](https://acl-bg.org/proceedings/2025/LowResNLP%202025/pdf/2025.lowresnlp-1.10.pdf)  
56. How Sensitive Are Large Multimodal Models to Prompts? \- arXiv, accessed January 26, 2026, [https://arxiv.org/html/2509.03986v1](https://arxiv.org/html/2509.03986v1)  
57. The ablation study results on different prompt engineering techniques, accessed January 26, 2026, [https://www.researchgate.net/figure/The-ablation-study-results-on-different-prompt-engineering-techniques\_tbl2\_380974537](https://www.researchgate.net/figure/The-ablation-study-results-on-different-prompt-engineering-techniques_tbl2_380974537)