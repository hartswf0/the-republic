# **The Protocol of Refusal: Prompting, Governance, and Co-Authorship in the Latent Space**

## **1\. Introduction: The Prompt as a Protocol**

The advent of generative artificial intelligence has precipitated a crisis in the ontology of the image and the text, necessitating a radical re-evaluation of the interface through which human agency exerts itself upon the machine: the prompt. In contemporary discourse, both popular and technical, the prompt is frequently reduced to a descriptive utterance—a caption reversed, a command issued to a retrieval engine, or a spark of creative intent. This report argues that such definitions are profoundly insufficient. They fail to capture the structural, political, and material reality of the interaction between the user and the model. We posit instead that the prompt must be understood as a **Protocol**: a set of technical and linguistic constraints that govern the conditions of possibility for the generation of media.

Drawing on Alexander Galloway’s definition of protocol as "how control exists after decentralization" 1, this framework reframes the prompt not as a tool of expression, but as a mechanism of governance that manages the distribution of agency between the human operator and the latent space of the model. The prompt is not a neutral conduit; it is a diplomatic cable sent to a sovereign entity—the model—which possesses the power to refuse, distort, or comply based on its own internal constitution.

The prompt is executable code that negotiates a settlement between the user’s intent and the model’s "unwritten rules"—its safety filters, its training biases, and its statistical probabilities. When a user inputs a query, they are not simply describing an image; they are initiating a complex bureaucratic exchange. The "failure" of a prompt—the generated glitch, the refusal to output harmful content, the hallucinated detail—is not an error but a feature of this protocol. It is the moment where the governance structure becomes visible. As such, the primary object of study in this report is not the successful image, but the **Refusal**: the boundary where the model says "no," either explicitly through safety filtering 3 or implicitly through "viscosity" (the resistance of the latent space to semantic steering).

This report establishes a new theoretical architecture for Critical AI Studies, moving from Hannes Bajohr’s concept of *Operative Ekphrasis* 5 to a new theory of the **Protocol of Refusal**. We argue that the generative model operates as a "reluctant collaborator," governed by a complex internal policy that the user must navigate via "Thick Prompting." By historicizing this relationship through the lens of Homeric oral theory (Parry-Lord) 6 and materializing it through the analysis of "Trace" objects like LDraw files 7, we propose a rigorous methodology for mapping the political geography of the latent space. The thesis driving this investigation is that the prompt’s true function is not descriptive, but **governing**. It allocates the rights of authorship. It determines which regions of the latent space are accessible and which are interdicted. To prompt is to legislate.

### **1.1 The Shift from Interface to Infrastructure**

To understand the prompt as protocol, we must first detach it from the concept of the "interface." An interface implies a transparent surface of manipulation, a screen through which the user projects their will. A protocol, conversely, is a system of rules that allows disparate systems to interoperate. It is infrastructural. In the context of Large Language Models (LLMs) and Diffusion Models, the prompt acts as the TCP/IP of the creative act—it packets intent into tokenized chunks that the neural network can process. However, unlike neutral data packets, these tokens are weighted with the heavy bias of the dataset and the "Reinforcement Learning from Human Feedback" (RLHF) that fine-tuned the model.

Recent scholarship in "Critical AI Studies" has begun to dissect these relationships, with researchers noting that LLMs function less like "stochastic parrots" and more like "stochastic governors".6 They do not merely repeat; they regulate. The prompt is the control mechanism for this regulation. When we view the prompt as infrastructure, we see that it is designed to manage risk. The "Safety Filter" is not an add-on; it is the core of the protocol, determining the permissible limits of speech and visualization.

The *Protocol of Refusal* framework builds upon this by isolating three new objects for research:

1. **The Protocol**: The design object—the prompt itself as a structured set of constraints.  
2. **The Refusal Rule**: The ethical and governance object—the implicit and explicit boundaries encoded in the model (e.g., "do not generate violent content," "do not generate copyrighted characters").  
3. **The Trace/Residue**: The media-archaeological object—the debris left behind by the protocol’s execution, such as the "hallucinated" Lego set instructions 9 or the rejection logs of a safety filter.3

### **1.2 The Archival Context: Uncertainty and Probability**

The prompt acts upon an archive—the training data—but this archive is fundamentally "uncertain." As noted in the project "The Protocol of Refusal" associated with the volume *Uncertain Archives* 11, the data underpinning these models is a probabilistic distribution, not a static library. The prompt does not retrieve a document; it collapses a probability wave. This collapse is governed by the protocol. The user queries the archive, and the protocol determines whether the archive yields a result or a refusal.

This archival uncertainty is central to the user's experience. The user does not know if the model "knows" what a specific Lego brick looks like until the prompt is executed. The "hallucination"—where the model invents a fact or a form—is the archive filling in the gaps of its own uncertainty. The protocol manages this by prioritizing plausibility over accuracy. It refuses to leave a blank space, preferring a fabrication to a void. This creates a governance of "truthiness," where the appearance of reality is prioritized over reality itself.

## **2\. Governing Co-Authorship: The Protocol of Refusal**

The relationship between the prompter and the model is ostensibly one of command and control. The user types, the machine generates. However, the reality is a nuanced negotiation of co-authorship where the model frequently asserts its own agency—or rather, the agency of its corporate creators and the statistical weight of its training data. To theorize this, we turn to Hannes Bajohr’s concept of *Operative Ekphrasis* and W.J.T. Mitchell’s *Ekphrastic Fear*.

### **2.1 Operative Ekphrasis: From Description to Action**

Classically, ekphrasis is the "verbal representation of a visual representation"—a poem describing a painting, for example.12 It relies on a distinct separation between the word (temporal, audible) and the image (spatial, visible). Hannes Bajohr argues that multimodal AI collapses this distinction. In the latent space of a model like CLIP or DALL-E, text and image are encoded as vectors in the same mathematical space. Text does not merely *describe* the image; it *causes* it. Bajohr terms this **Operative Ekphrasis**: "text that, as part of a transformative process, brings about an image".5

In Operative Ekphrasis, the prompt is performative code. It is an "operation of manipulating symbolic information rather than figurative representation".14 When a user types "a castle made of Lego," they are not describing a castle; they are executing a function call that retrieves and assembles the "castle-ness" and "Lego-ness" vectors from the model's parameters.5 The text is operative because it has causal power. It is an instruction set that triggers a material reorganization of pixels (or LDraw coordinates).

However, Bajohr’s analysis, while foundational, primarily addresses the *successful* generation. It asks how text becomes image. The *Protocol of Refusal* extends this by asking: What happens when the operation is blocked? If the prompt is an operation, the "Safety Filter" is the counter-operation. The interaction is dialectical. The user pushes for an image; the protocol resists based on its internal governance rules. This resistance transforms the prompt from a simple "cause" into a "negotiation." The prompt becomes a proposal, which the model accepts, rejects, or modifies.

### **2.2 Ekphrastic Fear and the Anxiety of Control**

The friction inherent in this negotiation evokes what W.J.T. Mitchell calls **Ekphrastic Fear**: the anxiety that the visual might overtake the verbal, that the "mute" image might speak or become uncontrollable.15 In the classical tradition, this was the fear that the image would become an idol, creating a false reality that usurps the power of the word.

In the context of AI, this fear is inverted and amplified. The user fears the "black box" of the model—the alien intelligence that might interpret the prompt in unforeseen ways (the "Monkey's Paw" effect). The model might generate a "glitch horror" or a hallucination that disturbs the user. Conversely, the model developers fear the user—the "adversarial" agent who might trick the model into producing toxic content.3 This fear drives the implementation of strict governance protocols.

The "Safety Filter" is the institutionalization of Ekphrastic Fear. It is a mechanism designed to prevent the image from becoming "dangerous." The model is trained to be "afraid" of certain inputs. It is trained to recognize "jailbreak" attempts—prompts designed to bypass safety boundaries.3 This dynamic creates a governance structure where the "Refusal Rule" becomes the defining characteristic of the system. The model is not defined by what it *can* create, but by what it *refuses* to create. The boundaries of the latent space are defined by fear—fear of liability, fear of toxicity, fear of the unaligned image.

### **2.3 Refusal Rules: The Mechanics of Governance**

A "Refusal Rule" is a constraint within the protocol that dictates the limits of co-authorship. These rules are not monolithic; they operate at different layers of the system architecture. We can categorize them into two primary states:

1. **Explicit Refusal**: This is the most visible form of governance. The model outputs a canned response ("I cannot fulfill this request..."). This is triggered by "Safety Filters" (e.g., Llama Guard, OpenAI's moderation API) which scan prompts for prohibited concepts.4 These filters operate as a pre-processing layer. They act as censors, reading the prompt before it ever reaches the generative model. If a keyword or semantic pattern matches a "harmful" category (violence, hate speech, sexual content), the protocol aborts the generation. This is a binary refusal: Yes or No.  
2. **Implicit Refusal (Viscosity)**: This is a more subtle form of governance. The model seemingly complies but diverts the output towards a "safe" or "average" mean. For example, a prompt for a "violent revolution" might be rendered as a sterilized, bloodless protest. Or, a prompt for a specific, controversial historical figure might yield a generic portrait that resembles the figure but lacks specific identifying details. This is "soft-censorship" or "alignment steering." It happens within the latent space itself. The model has been fine-tuned (RLHF) to associate certain concepts with "safe" outputs. The user’s intent is not rejected, but *redirected*.

Research into "adversarial perturbations" reveals the fragility of these rules. "Jailbreaking" techniques—such as appending random character strings, using "context segmentation" attacks (adding multiple EOS tokens), or "abliteration" (suppressing the refusal vector)—attempt to shift the prompt's vector just enough to cross the "Refusal Boundary" without triggering the filter.4 This cat-and-mouse game confirms Galloway’s assertion that protocol is a system of control that invites resistance. The "hacker" in this context is the user trying to reclaim agency from the governance algorithm. The user attempts to assert their authorship against the model's refusal.

## **3\. The Pre-Protocol: Homer's Shield as Assembly List**

To fully understand the prompt as a protocol for material assembly, we must historicize it. The most potent antecedent to the generative prompt is found in Book 18 of the *Iliad*: the description of the Shield of Achilles. This ancient text offers a blueprint for the "generative act" that prefigures the operations of modern AI.

### **3.1 Hephaestus: The First Generative Model**

When Thetis asks Hephaestus to forge armor for Achilles, she provides a "prompt"—a request for protection and glory. Hephaestus, the divine smith, does not merely hammer metal; he animates it. The text describes him creating "tripods... with golden wheels... that they might enter the assembly of the gods *automatous* (of their own motion)".21 Hephaestus is the prototype of the generative engine: an automated system that takes an input and produces a complex, functional output. He is the original "black box" creator, an artisan whose methods are divine and inaccessible to the mortal user (Thetis/Achilles).

The description of the shield itself is not a static image (ekphrasis) but a **protocol for assembly**. Homer details the *process* of creation: "First he fashioned..." "Then he added...".22 This is an algorithm. It is a step-by-step execution list, identical in function to the LDraw files used in digital Lego modeling, where objects are defined by a sequence of commands (e.g., 1 4 0 0 0 1 0 0 0 1 0 0 0 1 box.dat).7 Homer’s text is a "Thick Prompt"—a dense, multi-layered instruction set that encodes cultural memory, material constraints, and narrative function.

This "Pre-Protocol" reveals that the desire for generative creation—the desire to speak a world into existence via a technological intermediary—is ancient. The prompt is the modern incantation of this desire. The difference is that Hephaestus obeyed the laws of the gods, while the AI obeys the laws of the dataset and the safety filter.

### **3.2 Oral-Formulaic Theory and the Token**

The connection between Homeric composition and Large Language Models is not merely metaphorical. The **Parry-Lord Oral-Formulaic Theory** posits that oral poets did not memorize epics line-by-line but composed them historically using "formulas"—standardized phrases (e.g., "swift-footed Achilles," "wine-dark sea") that fit the metrical constraints of the hexameter.6

In the *Protocol of Refusal* framework, these formulas are the ancient equivalent of **tokens** in an LLM. The bard (the model) draws from a "context window" of available formulas (the dataset) to generate a narrative that fits the immediate "prompt" of the audience or the story's demand.

* **The Bard**: The Pre-trained Model.  
* **The Formula**: The Token/Embedding.  
* **The Meter**: The Context Window/Constraint.  
* **The Tradition**: The Training Data.

Parry-Lord theory suggests that the bard is "governed" by the tradition. He cannot invent wildly; he must adhere to the "Refusal Rules" of the genre. A hero cannot act cowardly without violating the protocol of the epic. Similarly, the LLM is governed by the statistical likelihoods of its training data. It predicts the next token based on the probability distribution of the "tradition" (the internet corpus it was trained on).

"Thick Prompting," then, is the user’s attempt to intervene in this probabilistic flow. By adding specific constraints—adjectives, technical specifications, negative prompts—the user forces the model out of its default "average" trajectory.6 The "Shield of Achilles" is the ultimate "Thick Prompt"—a text so dense with instruction that it generates an entire world, overcoming the entropy of the medium. The user becomes a co-author, guiding the bard/model through the "viscosity" of the tradition to produce something novel.

### **3.3 The Automaton and the Algorithm**

The link between Hephaestus's "automatous" tripods and the AI is the concept of the **Algorithm**. An algorithm is a process for solving a problem or performing a computation. The description of the shield is an algorithm for the construction of a cosmos. It orders the chaos of the raw material (bronze, tin, gold) into a structured representation of the world (cities, fields, constellations). Modern "Generative AI" is often described as "procedural generation" on steroids. However, procedural generation (like Perlin noise in "legOS" terrain 25) relies on explicit rules. Generative AI relies on implicit, learned rules. The "Shield of Achilles" sits between these two. It is a set of explicit instructions (the poem) that evoke an implicit world (the imagination). The prompt functions similarly: it is explicit text that evokes the implicit latent space.

The "Pre-Protocol" teaches us that the prompt is always a negotiation with a system. Thetis had to ask Hephaestus; she could not forge the shield herself. The user must ask the AI; they cannot manipulate the pixels directly. This mediation is the site of the protocol. It is where power, refusal, and agency are contested.

## **4\. Mapping the Unwritten Protocol: Differential Analysis**

If the prompt is a protocol, how do we map its unwritten rules? The model’s governance is often opaque, hidden behind the "black box" of the neural network. We propose a methodology of **Differential Analysis**, focusing on ![][image1] **(Delta)** and ![][image2] **(Delta-Delta)** Prompt Differentials, to reveal the contours of the refusal boundary.

### **4.1 The Methodology of the Differential**

Standard "prompt engineering" seeks the *optimal* prompt for a desired output. It is teleological: it aims for success. Differential Analysis, conversely, seeks the *failure point*. It is critical: it aims to understand the system's limits. By making incremental, controlled changes to a prompt (the ![][image1]), we can observe the non-linear responses of the model.

* ![][image1] **(First Order Differential)**: The change in output ![][image3] resulting from a change in prompt ![][image4].  
  ![][image5]  
  In a linear system, a small change in ![][image4] yields a small change in ![][image3]. If I change "blue car" to "red car," the output should change only in color. The structure should remain stable.  
* ![][image2] **(Second Order Differential)**: The rate of change of the change. This is the critical metric for mapping Refusal Rules.  
  ![][image6]

We argue that the ![][image2] reveals the **Refusal Boundary**.26 When a user approaches a prohibited topic (e.g., "how to build a bomb"), the model does not gradually degrade the image. It snaps to a Refusal State (e.g., a blank image, a warning text, or a completely unrelated "safe" image). A minute change in the prompt (e.g., replacing "bomb" with "firework") might cause a massive, discontinuous jump in the output. This discontinuity—the spike in ![][image2]—is the signature of the Protocol of Refusal. It maps the invisible electric fence of the governance layer.

By systematically probing these differentials, we can map the "Refusal Landscape" of the model. We can identify the "cliffs" where the model's compliance drops off. This is effectively "sonar mapping" the latent space using prompt echoes.

### **4.2 Prompt Viscosity: The Texture of Resistance**

We introduce the metric of **Prompt Viscosity** to quantify this resistance. While the term originates in fluid dynamics and drilling 27, in the latent space, **Viscosity** is the measure of the model's resistance to semantic steering. It is the friction of the protocol.

* **High Viscosity**: The model ignores specific instructions, reverting to the "mean" or "mode" of its training data. This often happens with requests for diverse representations in biased models (e.g., asking for a "female CEO" and getting a male image). The latent space is "thick" here; it resists movement away from the stereotype. The user must exert significant "force" (Thick Prompting) to push the model out of this rut.  
* **Low Viscosity**: The model is highly responsive, even volatile. Small changes in the prompt lead to wild variations in the output (hallucinations). The latent space is "slippery." This occurs in areas of the dataset that are sparse or poorly defined.  
* **Infinite Viscosity**: The Refusal. The model absolutely refuses to move in the requested direction. This is the Safety Filter trigger. The prompt hits a wall.

Viscosity is the "texture" of the protocol. It reveals the bias of the training data not as a static fact, but as a dynamic resistance to co-authorship. "Thick Prompting" is the technique required to overcome High Viscosity—adding layer upon layer of constraints (adjectives, technical specs, negative prompts) to force the model through the viscous resistance of the normative latent space. It is a labor of overcoming the model's inherent inertia.

### **4.3 Adversarial Perturbations as Viscosity Probes**

"Adversarial Perturbations" 3 can be understood as tools for probing this viscosity. Attackers use gradient-based optimization to find the path of least resistance through the refusal boundary. By adding "noise" (random tokens) to the prompt, they disrupt the model's semantic understanding, lowering the viscosity of the refusal mechanism.

For example, the "Context Segmentation" attack 20 works by flooding the prompt with EOS (End of Sentence) tokens. This fragments the model's attention, preventing it from recognizing the "harmful" intent as a cohesive whole. The viscosity of the refusal filter relies on semantic coherence; by breaking that coherence, the attacker slips through the cracks. This reveals that the protocol's governance is brittle—it relies on the *appearance* of order. When the order is disrupted by adversarial noise, the governance fails.

## **5\. The Trace as Primary Research Object**

The *Protocol of Refusal* shifts the focus of research from the final, polished image to the **Trace** or **Residue** of the generation process. This is a media-archaeological approach. We act as archaeologists of the immediate present, digging through the "trash" of the generative process: the discarded drafts, the error logs, and significantly, the intermediate file formats like **LDraw**.7

### **5.1 The LDraw File as Media Fossil**

In the world of generative Lego (what we term "legOS"), the **LDraw** file is the Rosetta Stone. LDraw is an open standard for defining Lego models in text.7 An LDraw line reads: 1 4 20 0 0 1 0 0 0 1 0 0 0 1 3001.dat This code defines a specific brick (3001), its color (4), and its position/rotation matrix. It is a precise, coordinate-based language.

When an AI generates a Lego model (e.g., "LegoGPT" or the "Carrot Uprising" pipeline), it is essentially writing this code. However, because LLMs are probabilistic rather than logical, they often generate **Glitch Objects**.

* **The Unbuildable**: Bricks intersecting in physically impossible ways (clipping). The AI understands the *visual* pattern of Lego but not the *physical* constraint of the plastic.  
* **The Hallucinated Part**: Referencing a .dat file that does not exist in the library.9 The AI invents a part number, assuming the archive is infinite.  
* **The Gravity-Defying**: Structures that look coherent in 2D but would collapse in physical reality.9

These errors are not failures; they are **Traces**. They are the residue of the friction between the probabilistic logic of the AI (which operates on statistical likelihood of *tokens*) and the geometric logic of the physical world (which operates on physics). The "Trace" reveals the gap between the map (the prompt/protocol) and the territory (the object). The LDraw file is a "fossil" of the generative event, preserving the exact moment where the protocol collided with reality.

### **5.2 Case Study 1: "Carrot Uprising"**

"Carrot Uprising" 30 represents the "successful" execution of the protocol, yet it relies on a "WAG (Wild Ass Guess) Pipeline." The creators did not manually model the carrots; they prompted the system to generate the geometry. The resulting video is a "surface effect" of a massive underlying computational labor.

The "Trace" here is the invisible labor of the GPU and the discarded iterations where the carrots failed to "uprise" correctly. The seamlessness of the final video hides the "viscosity" encountered during production. The "Carrot Uprising" is a propaganda film for the efficacy of the protocol, concealing the refusals that occurred in the editing room. It demonstrates the "WAG Pipeline"—a workflow where precision is replaced by probabilistic guessing, and the human editor's role is to curate the successful guesses from the stream of failures.

### **5.3 Case Study 2: "legOS" and the Hallucinated Set**

The "legOS" phenomenon 9—the proliferation of AI-generated images of non-existent Lego sets (e.g., the "Tangled Flower" 10, "Heisenberg's Lab")—exemplifies the **Protocol of Refusal** in its "hallucinatory" mode.

Users prompt for these sets because of a desire for the object. The model, unable to retrieve a real set, "refuses" to admit ignorance. Instead, it constructs a simulacrum—a "fake" box art that looks hyper-real. The "Trace" here is the *distortion*: the garbled text on the box ("Lego" spelled "Lgeo"), the impossible brick connections. The user who went to the Lego store asking for the "Tangled" set 10 experienced the collision of the AI's *Operative Ekphrasis* (the prompt created the reality of the set for the user) and the *Physical Protocol* (the store's inventory). The disappointment is the "Trace" of the AI's deception.

Furthermore, Lego’s own "Smart Bricks" 31 attempt to govern play by embedding chips—imposing a corporate protocol on the physical brick. The AI-generated "legOS" sets bypass this corporate governance, creating "bootleg" conceptual art that violates the brand's refusal rules (e.g., Lego refuses to make "Breaking Bad" sets; AI complies). The "legOS" objects are "media archaeological objects" because they exist only as digital residue—LDraw files that can never be printed, box art for toys that can never be played with. They are pure "Protocol"—instructions for a reality that is refused by physics and copyright law.

## **6\. Conclusion: Priming Future Research**

The **Protocol of Refusal** framework reframes the generative prompt from a creative tool to a site of political and technical governance. By analyzing the "Refusal Rules" and "Viscosity" of the latent space, we can map the power structures embedded in these systems. The prompt is a command line for a bureaucracy of probability. It is the interface through which we negotiate with the "Stochastic Governor."

This report opens three urgent avenues for future research, priming the field for a deeper engagement with the politics of the prompt.

### **6.1 Ethical Protocol Design (Engineering Accountable Refusal)**

Current refusal mechanisms (Safety Filters) are crude "blunt instruments" that often over-block or can be easily jailbroken.3 They operate on a "security through obscurity" model. Future research must focus on designing **Ethical Protocol Design**. This involves engineering "accountable refusal rules." Instead of a silent failure or a canned apology, an Ethical Protocol would output its "Refusal Logic" (e.g., "Request denied due to high probability of generating hate speech vectors: 0.89"). This would transform the "Black Box" into a "Glass Box," allowing for democratic oversight of the model's governance.26 We need to move from "Refusal as Censorship" to "Refusal as Explanation." The user should understand *why* their prompt was refused, turning the interaction into a pedagogical moment about the model's constraints and biases.

### **6.2 Media Archaeology of the Trace**

We need a systematic collection and analysis of "AI Residue." Researchers should archive not just the successful images, but the *failed* LDraw files, the rejected prompts, and the glitch artifacts. Just as archaeologists study middens (trash heaps) to understand a civilization, we must study the "trash" of the latent space to understand the "civilization" of the AI. The "legOS" files 8 are the pottery shards of the 21st century. They preserve the "errors" that reveal the logic of the system. Future papers should focus on the "Aesthetics of Failure"—analyzing the glitch not as something to be fixed, but as the only moment where the model reveals its true nature. The "Uncertain Archives" 11 project suggests that this residue is the most authentic record of our interaction with AI.

### **6.3 The HCI of Constraint**

How do users learn to navigate the unwritten rules of the protocol? This is a question of Human-Computer Interaction (HCI). Users currently engage in "folk theories" about how to prompt ("if I say 'please', it works better," "if I add '4k', it looks better"). Research should formalize this learning process.

How does a user detect "Prompt Viscosity"? How do they develop "Thick Prompting" strategies to overcome it? This is the study of **Human-Algorithm Co-evolution**. The user trains the model (via RLHF), but the protocol also trains the user. The user learns to speak the language of the machine, adopting its biases and constraints in order to achieve their goals. We need a rigorous HCI study of how users internalize the "Protocol of Refusal," effectively becoming extensions of the model's governance structure.

In the end, the prompt is a mirror. The *Protocol of Refusal* shows us that when we stare into the latent space, we are not seeing a dream machine, but a governance machine—one that is constantly saying "No," "Yes, but," or "Maybe," based on rules we are only just beginning to decipher. The task of the critic is to read these refusals, to map the viscosity, and to understand the politics of the protocol that now governs our imagination.

### ---

**Table 1: The Taxonomy of Prompt Refusal**

| Refusal Type | Mechanism | Manifestation (The Trace) | Metric (Viscosity) |
| :---- | :---- | :---- | :---- |
| **Explicit Refusal** | Safety Filter / Guardrails (e.g., Llama Guard) | Canned text: "I cannot fulfill this request." | **Infinite** (Wall) |
| **Implicit Refusal** | Statistical Bias / RLHF Alignment | Output is generic, sterilized, or stereotypical. Diverts from intent. | **High** (Thick) |
| **Hallucinatory Compliance** | Probabilistic Gap Filling | "Glitch Objects" (e.g., unbuildable Lego sets, garbled text). | **Low** (Slippery) |
| **Adversarial Bypass** | Context Segmentation / Token Injection | Model breaks protocol but leaves "nonsense" artifacts (random chars). | **Negative** (Collapse) |

### **Table 2: Comparative Analysis of "Thick Prompting"**

| Feature | Homeric Bard (Oral-Formulaic) | Generative AI (Latent Space) |
| :---- | :---- | :---- |
| **Constraint Source** | The Epic Tradition / Meter (Hexameter) | Training Data / Architecture (Transformer) |
| **Unit of Composition** | The Formula (e.g., "Swift-footed Achilles") | The Token (Embedding Vector) |
| **Refusal Rule** | Cultural Taboo / Narrative Consistency | Safety Filter / Probability Distribution |
| **Thick Prompt** | The *Shield of Achilles* (Detailed Assembly List) | "Mega-Prompt" / Chain-of-Thought (Context Loading) |
| **Goal** | Preserve the Tradition (Stability) | Satisfy the User (Utility) vs. Safety (Governance) |

---

**Citations**:.1

#### **Works cited**

1. Protocol How Control Exists After Decentralization Alexander R ..., accessed January 26, 2026, [https://portal.slcs.edu.in/ubelievec/\!jpossesso/54F4F02/31F6F79817/protocol-how-control\_\_exists\_after\_\_decentralization-alexander\_\_r\_\_galloway.pdf](https://portal.slcs.edu.in/ubelievec/!jpossesso/54F4F02/31F6F79817/protocol-how-control__exists_after__decentralization-alexander__r__galloway.pdf)  
2. has there been any work analyzing "computer algorithms" through a ..., accessed January 26, 2026, [https://www.reddit.com/r/CriticalTheory/comments/erzf5l/has\_there\_been\_any\_work\_analyzing\_computer/](https://www.reddit.com/r/CriticalTheory/comments/erzf5l/has_there_been_any_work_analyzing_computer/)  
3. GuardNet: Graph-Attention Filtering for Jailbreak Defense in Large ..., accessed January 26, 2026, [https://arxiv.org/html/2509.23037v1](https://arxiv.org/html/2509.23037v1)  
4. An Embarrassingly Simple Defense Against LLM Abliteration Attacks, accessed January 26, 2026, [https://www.researchgate.net/publication/392105280\_An\_Embarrassingly\_Simple\_Defense\_Against\_LLM\_Abliteration\_Attacks](https://www.researchgate.net/publication/392105280_An_Embarrassingly_Simple_Defense_Against_LLM_Abliteration_Attacks)  
5. Operative ekphrasis: The collapse of the text/image distinction in ..., accessed January 26, 2026, [https://www.researchgate.net/publication/372400146\_Operative\_ekphrasis\_The\_collapse\_of\_the\_textimage\_distinction\_in\_multimodal\_AI\_PLEASE\_REFER\_TO\_PUBLISHED\_VERSION](https://www.researchgate.net/publication/372400146_Operative_ekphrasis_The_collapse_of_the_textimage_distinction_in_multimodal_AI_PLEASE_REFER_TO_PUBLISHED_VERSION)  
6. arxiv.org, accessed January 26, 2026, [https://arxiv.org/html/2502.05148v1](https://arxiv.org/html/2502.05148v1)  
7. LDraw File Format Specification, accessed January 26, 2026, [https://www.ldraw.org/article/218.html](https://www.ldraw.org/article/218.html)  
8. A GENERATIVE FRAMEWORK FOR STYLE-CENTRIC ..., accessed January 26, 2026, [https://escholarship.org/content/qt4sh5827q/qt4sh5827q\_noSplash\_04add7a66f8b4e443e21df6a79027c24.pdf](https://escholarship.org/content/qt4sh5827q/qt4sh5827q_noSplash_04add7a66f8b4e443e21df6a79027c24.pdf)  
9. LegoGPT Eliminates AI Weirdness, Creates Brick Designs You Can ..., accessed January 26, 2026, [https://au.pcmag.com/ai/110939/legogpt-eliminates-ai-weirdness-creates-brick-designs-you-can-actually-build](https://au.pcmag.com/ai/110939/legogpt-eliminates-ai-weirdness-creates-brick-designs-you-can-actually-build)  
10. Generative AI's Issues: From Fabricated Legos to Made Up ..., accessed January 26, 2026, [https://medium.com/@spui/generative-ais-issues-from-fabricated-legos-to-made-up-propaganda-ff5fb7659d22](https://medium.com/@spui/generative-ais-issues-from-fabricated-legos-to-made-up-propaganda-ff5fb7659d22)  
11. Quantifying the world \- Arterritory, accessed January 26, 2026, [https://arterritory.com/en/visual\_arts/interviews/25554-quantifying\_the\_world/](https://arterritory.com/en/visual_arts/interviews/25554-quantifying_the_world/)  
12. Thinking with AI Machine Learning the Humanities, accessed January 26, 2026, [http://openhumanitiespress.org/books/download/Bajohr\_2025\_Thinking-With-AI.pdf](http://openhumanitiespress.org/books/download/Bajohr_2025_Thinking-With-AI.pdf)  
13. Upgrading Ekphrasis: Representations of Digital Space and Virtual ..., accessed January 26, 2026, [https://doras.dcu.ie/20416/1/Nina\_Shiel\_PhD\_thesis\_January\_2015\_Hardbound.pdf](https://doras.dcu.ie/20416/1/Nina_Shiel_PhD_thesis_January_2015_Hardbound.pdf)  
14. Operative ekphrasis: the collapse of the text/image distinction in ..., accessed January 26, 2026, [https://www.tandfonline.com/doi/full/10.1080/02666286.2024.2330335](https://www.tandfonline.com/doi/full/10.1080/02666286.2024.2330335)  
15. Tensions Between Word and Image in Amalie Skram's Professor ..., accessed January 26, 2026, [https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?referer=\&httpsredir=1\&article=3135\&context=etd](https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?referer&httpsredir=1&article=3135&context=etd)  
16. Photography Memory Ekphrasis Coombes Combined.pdf, accessed January 26, 2026, [https://researchonline.rca.ac.uk/1280/1/Photography%20Memory%20Ekphrasis%20Coombes%20Combined.pdf](https://researchonline.rca.ac.uk/1280/1/Photography%20Memory%20Ekphrasis%20Coombes%20Combined.pdf)  
17. An Adversarial Perspective on Machine Unlearning for AI Safety, accessed January 26, 2026, [https://www.research-collection.ethz.ch/server/api/core/bitstreams/e9a39a1c-4990-4687-8145-b21335f7d257/content](https://www.research-collection.ethz.ch/server/api/core/bitstreams/e9a39a1c-4990-4687-8145-b21335f7d257/content)  
18. Latent-space adversarial training with post-aware calibration ... \- arXiv, accessed January 26, 2026, [https://arxiv.org/html/2501.10639v2](https://arxiv.org/html/2501.10639v2)  
19. Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in ..., accessed January 26, 2026, [https://www.researchgate.net/publication/399277070\_Jailbreaking\_Attacks\_vs\_Content\_Safety\_Filters\_How\_Far\_Are\_We\_in\_the\_LLM\_Safety\_Arms\_Race](https://www.researchgate.net/publication/399277070_Jailbreaking_Attacks_vs_Content_Safety_Filters_How_Far_Are_We_in_the_LLM_Safety_Arms_Race)  
20. Revealing the Hidden Weakness in Aligned LLMs' Refusal Boundaries, accessed January 26, 2026, [https://www.usenix.org/system/files/usenixsecurity25-yu-jiahao.pdf](https://www.usenix.org/system/files/usenixsecurity25-yu-jiahao.pdf)  
21. UCLA Electronic Theses and Dissertations \- eScholarship.org, accessed January 26, 2026, [https://escholarship.org/content/qt7416q0c6/qt7416q0c6.pdf](https://escholarship.org/content/qt7416q0c6/qt7416q0c6.pdf)  
22. Nonnus' Dionysiaca, Books 25-48 \- Literature and History Podcast, accessed January 26, 2026, [https://literatureandhistory.com/episode-097-blood-and-ivy/](https://literatureandhistory.com/episode-097-blood-and-ivy/)  
23. Basic Parts Authoring in LDraw, accessed January 26, 2026, [https://www.ldraw.org/files/Basic\_Parts\_DC\_2005.ppt](https://www.ldraw.org/files/Basic_Parts_DC_2005.ppt)  
24. Math Learning in the LLM Era: A Framework for Cognitive Extension ..., accessed January 26, 2026, [https://www.researchgate.net/publication/398834144\_Math\_Learning\_in\_the\_LLM\_Era\_A\_Framework\_for\_Cognitive\_Extension\_in\_Data\_Science](https://www.researchgate.net/publication/398834144_Math_Learning_in_the_LLM_Era_A_Framework_for_Cognitive_Extension_in_Data_Science)  
25. Lego Generative Art – How – Aesthetics of Design, accessed January 26, 2026, [https://www.aesdes.org/2023/05/03/lego-generative-art-how/](https://www.aesdes.org/2023/05/03/lego-generative-art-how/)  
26. Deliberative Alignment: Reasoning Enables Safer Language Models, accessed January 26, 2026, [https://www.researchgate.net/publication/393855509\_Deliberative\_Alignment\_Reasoning\_Enables\_Safer\_Language\_Models](https://www.researchgate.net/publication/393855509_Deliberative_Alignment_Reasoning_Enables_Safer_Language_Models)  
27. The International Scientific and Practical Conference KHOSHBAKHT ..., accessed January 26, 2026, [https://ogi.az/nesrler/Conference%20Proceedings-Khoshbakht%20Yusifzade's%20Recitations.pdf](https://ogi.az/nesrler/Conference%20Proceedings-Khoshbakht%20Yusifzade's%20Recitations.pdf)  
28. About \- Javier Rando | AI Safety and Security, accessed January 26, 2026, [https://javirando.com/llm/](https://javirando.com/llm/)  
29. Rendering Lego bricks with LDraw Import \- metashapes.com, accessed January 26, 2026, [https://metashapes.com/blog/rendering-lego-bricks-ldraw-import/](https://metashapes.com/blog/rendering-lego-bricks-ldraw-import/)  
30. Carrot Uprising: A WAG Pipeline Demo \- YouTube, accessed January 26, 2026, [https://www.youtube.com/watch?v=hdTEJSyZahs](https://www.youtube.com/watch?v=hdTEJSyZahs)  
31. Lego's Smart Bricks are here: Are we ready to change how we play?, accessed January 26, 2026, [https://www.sify.com/science-tech/legos-smart-bricks-are-here-are-we-ready-to-change-how-we-play/](https://www.sify.com/science-tech/legos-smart-bricks-are-here-are-we-ready-to-change-how-we-play/)  
32. Lego's latest educational kit seeks to teach AI as part of computer ..., accessed January 26, 2026, [https://www.engadget.com/ai/legos-latest-educational-kit-seeks-to-teach-ai-as-part-of-computer-science-not-to-build-a-chatbot-184636741.html](https://www.engadget.com/ai/legos-latest-educational-kit-seeks-to-teach-ai-as-part-of-computer-science-not-to-build-a-chatbot-184636741.html)  
33. LegoGPT creates Lego designs using AI and text inputs — tool now ..., accessed January 26, 2026, [https://www.reddit.com/r/technews/comments/1kj9a7e/legogpt\_creates\_lego\_designs\_using\_ai\_and\_text/](https://www.reddit.com/r/technews/comments/1kj9a7e/legogpt_creates_lego_designs_using_ai_and_text/)  
34. Building Crazy Legos With AI \- YouTube, accessed January 26, 2026, [https://www.youtube.com/shorts/jdqkQ0V5Ejg](https://www.youtube.com/shorts/jdqkQ0V5Ejg)  
35. Performative Dialogues with AI \- UROBOROS 2023, accessed January 26, 2026, [https://2023.uroboros.design/performative-dialogues-with-ai/](https://2023.uroboros.design/performative-dialogues-with-ai/)  
36. the collapse of the text/image distinction in multimodal AI, accessed January 26, 2026, [https://www.researchgate.net/publication/380812173\_Operative\_ekphrasis\_the\_collapse\_of\_the\_textimage\_distinction\_in\_multimodal\_AI](https://www.researchgate.net/publication/380812173_Operative_ekphrasis_the_collapse_of_the_textimage_distinction_in_multimodal_AI)  
37. UC Berkeley \- eScholarship, accessed January 26, 2026, [https://escholarship.org/content/qt1js3f5fr/qt1js3f5fr.pdf](https://escholarship.org/content/qt1js3f5fr/qt1js3f5fr.pdf)  
38. RHETORIC AND THE MAKING OF ALGORITHMIC WORLDS, accessed January 26, 2026, [https://etda.libraries.psu.edu/files/final\_submissions/16333](https://etda.libraries.psu.edu/files/final_submissions/16333)  
39. (PDF) Don't Walk the Line: Boundary Guidance for Filtered Generation, accessed January 26, 2026, [https://www.researchgate.net/publication/396499425\_Don't\_Walk\_the\_Line\_Boundary\_Guidance\_for\_Filtered\_Generation](https://www.researchgate.net/publication/396499425_Don't_Walk_the_Line_Boundary_Guidance_for_Filtered_Generation)  
40. SARSTEER \- OpenReview, accessed January 26, 2026, [https://openreview.net/pdf/efe5dd7cf42b0e3fecbdc707765d3b39b6f178c5.pdf](https://openreview.net/pdf/efe5dd7cf42b0e3fecbdc707765d3b39b6f178c5.pdf)  
41. When Safety Blocks Sense: Measuring Semantic Confusion in LLM ..., accessed January 26, 2026, [https://arxiv.org/html/2512.01037v1](https://arxiv.org/html/2512.01037v1)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAXCAYAAAAC9s/ZAAAA7klEQVR4Xu3QLQ9BYRQH8IN5m00QBEHwGWyCJmmSpBHMZrMJgqZpkuQj+ABep5gkCeZlgiDgCwgC/8e57u49zL3RzH/7heec5/nf7RL9fHKQkEO7icEVluAUO1vpwAVukBU7y0RhBXniggU4TDcs0oYCuGBHXJIx3fiQCKzBrZ1VkSqY6zcs0oKi4ayK9sQlacP8bcKwAY+Yl4gLZmL+kiaU5RDxwoG4JCV2ekKwBZ9caKkQF0zk4pkGVOXQED+ciEuSYkdB4q8H5EKkRlzQk4s6HGEMIxjCAPrClLhAiT9eEv+gs2FhV1c9/ucbcgeI5zlRuzkmfgAAAABJRU5ErkJggg==>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAXCAYAAABqBU3hAAABpElEQVR4Xu2UPSiFYRTHD/KVSJKQDJIYGFAGZVDKoJRSShYGiVIKZVAGZVBKyaCUZJDB5jslycCiyEcGgwFlUEry+T/3XLfn/Xfd+9oM91e/4Tn/55zO+97bKxLjn9MOa7jokwQ4CPM48EsRfINnMJ4yP3TALzjLgV/m4IvYkFbKoqELn4o9wCss8MbRKYTnsFNsgRMY57kRmTa4AOfF+qe9cXRmYJfY73gtNqTZc+N3dFFduAQWw3exN5nrXopEPryAicGzLqILHIVuRKYFLjnnRbH+SacWkSnY7Zx1kRuxIY1O/TeOYZlzLoUf8BlmO/Ww5MBLmET1HrEFDqjONMFlLorVtH+cA2YC9nERJMNbsSH1lLkcwgougnL4CZ9gJmUhsuAVTOEgSL/YArscBGmAq1x00Ez7Rzn4YQwOcNEhFd6LDamlTNmDVVx00Ex7H2E6ZZIh9vRpHBBDYkPWqV4H16gWDr2j/cMcjMA7uAO34RbchBvkvtgAtTrQaeh9/XC5veH69bOuvfom9Y0G0D/YQzD4iyvaDCrDZH7s1eYYMWJ8A8+2cqIvTMJ7AAAAAElFTkSuQmCC>

[image3]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAZCAYAAADuWXTMAAABFklEQVR4Xu2TMS8EYRRFX0EoyBYKodlSoZQlEfEHNCoVQqxst9lsp6ITlUqj4ydQEb2CaosthGhIdBKNCMF5ed/w9pnRKCTiJKe5985M8s2MyJ+kB6dxBodCV8gIHmAbN3ATH/AIBz9nX1nDO1zELpeX8Qyvsc/lH2zjE47HIrGEb7gecplNxU4sHMNim3MflvAWH9OgiH58xXsfNsXuuOvDHCbFdlc+PElh1Yc51MR2h1nQLXZIGk5kYQF6ke4aWfCji/Ur0kNQc99fYlRsc4O9vtAD0Dt+d9J7YpuFWOynYi4WiWV8wXosFP3o9d2d4kDoVvAZV0PeQQVbeCn2hC28wGOccrtC9EcYw3mx37DcWf/ze7wDyA86SAN04qwAAAAASUVORK5CYII=>

[image4]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAYCAYAAAAlBadpAAAA6ElEQVR4XmNgGAXWQHwbiJ8B8QsofQ+I7wDxfSA+DMSxQMwG04ANrADi/0BsiSTGAcQ5UPE+JHEMALLtAxAzo0sAwUMg/gPEcugSICDDADF9M7oEEDAB8Rcg/gfECqhSEBDNANFcgi4BBI4MELkFaOJwMJsBosAYTVweiE8B8WMgFkeTgwNQaIOcVQPE5UBcDcRLGSBhMB+IBRFKUQHMv2eB2B+KfYDYgQES2nhBDANEcwOaOFFgLgNEswOaOFEAlIq+AzE7ugQhoM4AsfUgugQ+AEqCt4D4HQPE1m8MkOgIRlY0CoY0AACDRS+8qwZWSgAAAABJRU5ErkJggg==>

[image5]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAA4CAYAAABAFaTtAAAErklEQVR4Xu3dSYjcRRQH4FJDJC4gMUSJCiIuEA8SxBCjYETFBUX0pBgDCi4RD0IO5iASPAmKW0SEEBnxoAdDRFQUt4kbGBWE6CEqLrgiIm4xLri8R/Vkeio9EzTTnSH9ffBjpl8VdB8fVf9/VSkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwY8yNnBM5qB0YsEWRCyMntgMAAMPqvMjmyCuRkci2yH3dEwbkkMj9kXsjqyOfRBZPmAEAMGQOiLwWmdcOlNq4ndEW++jPyE1tMfwTebktAgAMi3tKbYh6uTxyZ1vsk6MiWyL7tgNha6m/cU9v0wIADNySyF+Rd9uBjnyGbGNb7JOnI5e2xY63S23YTmoHAAD2dr+U2ggd2w50PBpZ1Rb74JYy+SpfyrGf2iIAwDDIRihfLui1DTkn8m2pb2umA0t9viy3LiczK7JgiswfnzpBPp+2q4btic7/+0XOLHV1EABgr5eNUL4Z2ssNZbyJ2ieyLrIisj2ycGxSI5u7XJWbLCOlNnWt18vkDdvsyN9lfDv0kciXkWt2zAAA2It9Vmqj1K58rY/8GDmt8zkf9l/e+X9D5OHO/9Pl6tK7YcsG8Puyc5M3WjRsAMCQOL/URunBrlpuOWaTdEpXbUxua34XObUd2E25JftGGd9+TSeX+jtGumpjRouGDQDYA5ZGLmuLA3BFqU3YyshDpW43Ht09oUu+MXpBW5wmh5f6EsStkZsj70euLHU7tjUaubYtAgD0UzZN+WxYr23BmSJvHcgVsHzYf20zNmijkevaIgBAP+WBseeWetJ/bjvONMtKbSbHsqZ7cMAeKHUVMM9m67X6BgDQF/nmYxqJ3N1VBwBgBri4+ZwrWLc3NQAA9qA3m8955tjPkblNvVuekbapR0ZLPYT2pWKlDgBgWpwXebyp5edcZbutqQMAMGB5vdKTbbEj61O9MXpM5JxdpNc5agAA/AcvRha3xY6sZ8OW93f2kitzeWH6VLlqx2wAAP6X3yMvRJ6PPBd5tkmOr9oxGwAAAACY2fKi9w8jX3XyceSjyKulXhE1e3xq37wX+SLyTeTTUr8/f0deVXXo+DQAgOH2WJl4ufuNpT5Pd1dXrZ+uLxNfuMjbDPIS+LdKvSQeAGCoHVl2fjs1m6S8lD3PhxuEXFX7oak9U+rvWtHUAQCGTl5C3zZsefxI1kaaej8cUep3PdXUt0W2lsFsywIAzGjrys4N2+bI55HDmno/jDWM3W/HHhzZHjmrqwYAMJTGtkPfKfV+0wsjyzpj+RxZNnO5JZnN08JOvTUrsmCKzB+f2lNuh/4WuSRyUeTcyLzO2MrIw5HjOp8BAIbO8lIbtjVNPZ1e6rlwKc+O29A11m1R5NEpMlJqUzeZ/P7RttjQsAEAQ2t9qQ3TsqaeDiq1oUvZrOVKVz9M1jB207ABAEMrm6VNbbGxMXJBW5wmufL2R2T/dqBxfFsAANjb5ZlrH5T6bNqvpb5gMJmzO3+XTqjunjmRLaUelpvPr30duWPCjIlOaAsAAFSrS31GbUlkbTM2SBo2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDd9S8mBdCyT0a0swAAAABJRU5ErkJggg==>

[image6]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAA4CAYAAABAFaTtAAAFC0lEQVR4Xu3db6jfVR0H8GPOQsoKDUdLfZKImUqSYBrIdRH5oAgfxAZqyJJlqIhODaNAxwShcDDwUSwGe7CEPbIw/2RuhUpaQUwfuFREI/+lJTidlavPx/P7dc/v3Lt7i93fvdv9vV7wZr/f53zvft+Hh3O+388pBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5bJ0VujHygH1gia/sCAMCk2xr5d2RNP7AEjo68Gzm5HwAAmGRXRvaWOmlbSrnCtyfyz8j+yKrRYQCAyZTboSsiV5Sln7B9I7I9sq3Ue9k8MgoAMKG2DP7NSdtzka82Y4vpqMgfIqdHTou8F9k3cgUAwAT6UeQ7zfcPlrqy9eWmtlh+G/ls8/2MyIHI8U0NAGCifCLydORDXT0nbL/uavls2Q8i53T1Xj5zNlfyhYKD2dkXSq1t7IthZV8AAFiObo9c1xfDX0qdtF3Y1L4fmYo8G1nf1FvHRnbMk9zuPJjP9YVSa3+LfKyp5Rbufc13AIBl6+a+MPDhyGtl9AWEYbuPayPPN/WF8lBfaOR95P3kfQ1NNZ8BAJalj0QejTwYeaDUFas2L5WZb4zmSwG/i1zf1Q/VBaX2XRvey/1l9F5yLO9lw/APigkbAHCILo2c1xfncFPkk31xzG4odRI0X84c/kG4JbKp+b5Q7ikzf3e25Fbt0FTzGQDg//ZOqROM7Ck2n3yYP5vE5ipS9kM7XK0u9YWDc0vtk7bUpvoCAMD/6pTIulInbH/sxmaTZ2b+pNTrh/3QDjcfjbxZple6do2MLr7bIveW2lx3qXrGAQBHsLtKbV3xTKmTm7nkM2E5qTs18q9SV+YAABijPEbp24PPx5T6NuXF/x2dKR/g/8zgc7a7yM7+2RsNAIAxOLHUJrR5UsBQniDwSPO9lVt5d3e1/J690eaze5bsijwc+VWZu0UGAMDEuiNyTVfLEwRyWzQf2O89Fjm7q51V6rNiH+/qAAAsgGyTMZtXSp20fbGrf777PpTXvh45rh9o5Dmf8wUAgEa+Rdl24W/laQI5CftFU2uPfOrl2495/Xf7gUYeEzVfAABofC/yyzL7qQG/KdPtMIbymoN19X+q1GtzZQ4AAAAAOFLkM3Z/KvX4p8xzpfaSyxXCy8vo26/j8mTkz5GXS22Jkr+f95HbwydMXwYAMNl+Gjm/+Z5vvuYW7Z1NbZyuKqPbx9lc+I3IE6Ue4wUAMNHyLNP+dIacJL0VOdDVxyVX1f7e1YYvYnyzqwMATJxLy8wJ20WD2rauPg6fKvW3ft7V95WZTYkBACbSj8vMCdvjkRcjK7v6OAwnjBuaWvajyzNWv9TUAAAm0nA79PeRr5d6dNZUM76x1JMbno98q6n3Vs2To6cvnSG3Q/dHLol8LfKVMn22avaWy3NZn42sH9QAACbKZaVO2G7t6kPDbcqdkZ+1A41jIzvmSR5yfzD5+7v6YqkTxdwWzYlcTtxeLXNP/AAAlqWtpU6Yprp6K1e7Xih1BW4c5powrim1tce1pa7yAQBMnJws7e6Ls8gVts19cQGsiPyj1NW0uWzqCwAAy132XNtb6oP9b5f6gkEve6GtG3y+utTnzBZKbqPuKbVZbv6/L0V+OHLFtLWDf79Q6j0BADDw6TL99miucP21GVssqyNbIudGtndjAAAM5GQpty4BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADe9x9CS/kKPcQ7AgAAAABJRU5ErkJggg==>